[EVALUATION]
epochs        = 8
batch_size    = 128
preprocessing = None

[POPULATION]
bp_pop_size    = 25
mod_pop_size   = 45
genomes_per_bp = 4

[GENOME]
dtype                = 'float32'
available_modules    = ['DenseBlock']
available_optimizers = ['Adam']
#output_layers = [{'class_name': 'Flatten', 'config': {}},{'class_name': 'Dense','config': {'units': 5,'activation': 'sigmoid' }}]
output_layers = [    {'class_name': 'GlobalAveragePooling2D', 'config': {}},
    {'class_name': 'Dense','config': {'units': 128,'activation': 'relu'}},
    {'class_name': 'Dropout','config': {'rate': 0.5}},
    {'class_name': 'Dense','config': {'units': 5,'activation': 'sigmoid'}}]

[MODULE_SPECIATION]
mod_spec_type            = 'param-distance-dynamic'
mod_spec_species_count   = 4
mod_spec_distance        = 0.3
mod_spec_mod_elitism     = 2
mod_spec_min_offspring   = 1
mod_spec_reprod_thres    = 0.5
mod_spec_max_stagnation  = 15
mod_spec_species_elitism = 2
mod_spec_rebase_repr     = True
mod_spec_reinit_extinct  = False


[MODULE_EVOLUTION]
mod_max_mutation   = 0.3
mod_mutation_prob  = 0.8
mod_crossover_prob = 0.2


[BP_SPECIATION]
bp_spec_type            = 'gene-overlap-dynamic'
bp_spec_species_count   = 3
bp_spec_distance        = 0.3
bp_spec_bp_elitism      = 2
bp_spec_min_offspring   = 1
bp_spec_reprod_thres    = 0.5
bp_spec_max_stagnation  = 15
bp_spec_species_elitism = 2
bp_spec_rebase_repr     = True
bp_spec_reinit_extinct  = True


[BP_EVOLUTION]
bp_max_mutation            = 0.3
bp_mutation_add_conn_prob  = 0.2
bp_mutation_add_node_prob  = 0.2
bp_mutation_rem_conn_prob  = 0.05
bp_mutation_rem_node_prob  = 0.05
bp_mutation_node_spec_prob = 0.3
bp_mutation_optimizer_prob = 0.1
bp_crossover_prob          = 0.1

[MODULE_DENSEBLOCK]
# Specify the Dense Block parameters for CheXpert
growth_rate     = {'min': 16, 'max': 48, 'step': 4, 'stddev': 8}
num_layers      = {'min': 2, 'max': 10, 'step': 1, 'stddev': 1}
bottleneck      = [True, False]
compression     = {'min': 0.5, 'max': 1.0, 'step': 0.1, 'stddev': 0.1}
activation      = ['relu', 'elu']
dropout_flag    = 0.5
avg_pool_flag = 0.5
batch_norm      = 0.5
dropout_rate    = {'min': 0.1, 'max': 0.5, 'step': 0.1, 'stddev': 0.1}
kernel_init  = ['glorot_uniform', 'random_normal', 'he_normal']
bias_init    = ['zeros', 'ones']
num_dense_blocks = {'min': 2, 'max': 6, 'step': 1, 'stddev': 1}
kernel_size  = {'min': 1, 'max': 5, 'step': 1, 'stddev': 1}  # example values, adapt as needed
filters = {'min': 16, 'max': 128, 'step': 16, 'stddev': 16}

[OPTIMIZER_ADAM]
learning_rate = {'min': 0.0001, 'max': 0.01, 'step': 0.0001, 'stddev': 0.001}
beta_1        = {'min': 0.6, 'max': 1.5, 'step': 0.05, 'stddev': 0.2}
beta_2        = {'min': 0.8, 'max': 1.2, 'step': 0.001, 'stddev': 0.1}
epsilon       = {'min': 1e-8, 'max': 1e-7, 'step': 1e-8, 'stddev': 1e-7}
